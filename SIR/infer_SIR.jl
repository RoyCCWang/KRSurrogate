

import DifferentialEquations

import Printf
import PyPlot
import Random
import Optim

using LinearAlgebra

using FFTW

import Utilities
import Distributions

include("basic_model.jl")
include("parsers.jl")

PyPlot.close("all")
fig_num = 1

Random.seed!(25)

N_pop = 10000.0
I_0 = 10.0
R_0 = 0.0

S_0 = N_pop - I_0

#Î² = 1.22*N_pop/6
Î² = 0.22
Î³ = 1/6

discount_factor = 1.0

println("oracle: Î² = ", Î²)
println("oracle: Î³ = ", Î³)
println("oracle: S_0 = ", S_0)
println("oracle: I_0 = ", I_0)
println("oracle: R_0 = ", R_0)
println("oracle: k = ", discount_factor)
println("oracle: N_pop = ", N_pop)
println()

#Î¸ = [N_pop; Î²; Î³]
#u0 = [ð‘†_0; ð¼_0; ð‘…_0]

t0 = 0.0
t_end = 365.0
S_t, I_t, R_t = solveSIRnumerical(I_0, S_0, R_0,
                        Î², Î³, N_pop; t0 = t0, t_end = t_end)



Nq = 500
xq = LinRange(t0, t_end, Nq)

infected_xq = I_t.(xq)

PyPlot.figure(fig_num)
fig_num += 1

PyPlot.plot(xq, infected_xq, label = "I(t)")

PyPlot.title("I(t)")
PyPlot.legend()


#### generate data.
#N = 800 # gives a very degenerate posterior.
N = 5 #80
ð“£ = collect( Utilities.convertcompactdomain(
                                rand(),
                                0.0,
                                1.0,
                                t0,
                                t_end) for n = 1:N)

Ïƒ_Y = 20.0
Y = collect( discount_factor * I_t(ð“£[i]) + randn() * Ïƒ_Y for i = 1:N )

# conclusion: posterior is too ill-posed for direct density fitting.
# remedy: Gaussian flow, or some factorization approach.

#### unnormalized posterior density of parameters from evaluations of Y.
# when N is large, the unnormalized posterior density should be concentrated
#       at the oracle parameters.
# This tests the identifiability claims.

D = 2
const_params = [ discount_factor, N_pop, R_0, S_0, I_0 ]

Ïƒ = Ïƒ_Y + 1e-5
Î£_y = diagm( ones(N) .* Ïƒ^2 )

# debug.
dist_Î² = Distributions.Gamma(1.0, 1.0)
dist_Î³ = Distributions.Gamma(1.0, 1.0)

ln_p_Î² = Distributions.logpdf(dist_Î², Î²)
ln_p_Î³ = Distributions.logpdf(dist_Î³, Î³)


Î¼ = discount_factor .* I_t.(ð“£)
dist_y = Distributions.MvNormal(Î¼, Î£_y)
ln_likelihood = Distributions.logpdf(dist_y, Y)

res = Y-Î¼
prop_ln_likelihood = -dot(res, Î£_y\res)/2

Z = -0.5*logdet(Î£_y) -length(Y)/2 *log(2*Ï€)

A = prop_ln_likelihood+Z
println("ln_likelihood = ", ln_likelihood)
println("A = ", A) #should be same as ln_likelihood
println()

println("prop_ln_likelihood = ", prop_ln_likelihood)

@assert 1==2


# out, Î¼ = evalposteriorSIR([Î², Î³],
#                 const_params,
#                 parser2,
#                 Î£_y,
#                 Y,
#                 ð“£;
#                 t0 = 0.0,
#                 t_end = 365.0,
#                 Î²_prior_shape = 1.0,
#                 Î²_prior_scale = 1.0,
#                 Î³_prior_shape = 1.0,
#                 Î³_prior_scale = 1.0)
#
# #
# println("out = ", out)
# println("discrepancy between Î¼ and Y = ", norm(Î¼-Y))
# println()
#
# @assert 1==2

ln_f = xx->evalposteriorSIR(xx,
                    const_params,
                    parser2,
                    Î£_y,
                    Y,
                    ð“£;
                    t0 = 0.0,
                    t_end = 365.0,
                    Î²_prior_shape = 1.0,
                    Î²_prior_scale = 1.0,
                    Î³_prior_shape = 1.0,
                    Î³_prior_scale = 1.0)
#
f = xx->exp(ln_f(xx))

### sanity check.
x_max = [Î², Î³]
x_test = x_max + randn(D) .* 1e-3
println("ln_f(x_max)  = ", ln_f(x_max))
println("ln_f(x_test) = ", ln_f(x_test))
println()

### visualize.

limit_a = [0.0; 0.0]
limit_b = [0.5; 0.5]

N_array = [100; 100]
x_ranges = collect( LinRange(limit_a[d], limit_b[d], N_array[d]) for d = 1:D )

X_nD = Utilities.ranges2collection(x_ranges, Val(D))

#
f_X_nD = f.(X_nD)
fig_num = VisualizationTools.visualizemeshgridpcolor(x_ranges,
                            f_X_nD, [], ".", fig_num,
                            "f, unnormalized density")
#
ln_f_X_nD = ln_f.(X_nD)
fig_num = VisualizationTools.visualizemeshgridpcolor(x_ranges,
                            ln_f_X_nD, [], ".", fig_num,
                            "ln_f, unnormalized density")
#
println("oracle: Î² is ", Î²)
println("oracle: Î³ is ", Î³)
println()

# conclusion: posterior is too ill-conditioned for density fitting.
# just selecting kernel centers will be troublesome.
